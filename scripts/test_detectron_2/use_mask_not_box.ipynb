{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Get segmentations instead of boxes ?**"
      ],
      "metadata": {
        "id": "a1100bGQmLOt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM54r6jlKTII"
      },
      "source": [
        "# Install detectron2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1rV2ixNTFb-"
      },
      "source": [
        "**References :** https://github.com/facebookresearch/detectron2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsePPpwZSmqt"
      },
      "outputs": [],
      "source": [
        "!python -m pip install pyyaml==5.1\n",
        "import sys, os, distutils.core\n",
        "# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities (e.g. compiled operators).\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n",
        "!git clone 'https://github.com/facebookresearch/detectron2'\n",
        "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
        "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
        "sys.path.insert(0, os.path.abspath('./detectron2'))\n",
        "\n",
        "# Properly install detectron2. (Please do not install twice in both ways)\n",
        "# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d288Z2mF5dC",
        "outputId": "35f88a2e-8457-4d5e-fee7-a01fa1897bab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n",
            "torch:  2.1 ; cuda:  cu118\n",
            "detectron2: 0.6\n"
          ]
        }
      ],
      "source": [
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tL3UiRjja1aB"
      },
      "source": [
        "**Libs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZyAvNCJMmvFF"
      },
      "outputs": [],
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOmFpIZ4G6lw"
      },
      "source": [
        "##**Personal Goal âŽ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo2xRGUwGirO"
      },
      "source": [
        "**Here I Am going to personalize the work and get only Human detection as output.**\n",
        "\n",
        "**The input image will be cropped into N persons detected by Detectron2**\n",
        "\n",
        "**We will be adding variable N to calculate the occurence of the Humans in the pic**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk4gID50K03a"
      },
      "source": [
        "# Run a pre-trained detectron2 model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uM1thbN-ntjI"
      },
      "source": [
        "Then, we create a detectron2 config and a detectron2 `DefaultPredictor` to run inference on this image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUjkwRsOn1O0",
        "outputId": "9c01487c-08f4-498b-f0e9-370a0b41d68b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11/15 20:09:51 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "model_final_f10217.pkl: 178MB [00:01, 139MB/s]                           \n"
          ]
        }
      ],
      "source": [
        "cfg = get_cfg()\n",
        "\n",
        "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
        "\n",
        "# Load Model\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "\n",
        "# Create a predictor\n",
        "predictor = DefaultPredictor(cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHH42I0THsNV"
      },
      "source": [
        "-> so 0 stands for person"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2LeAcewBTf0"
      },
      "source": [
        "**FILTER PERSON ONLY**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bV0Ox61kTItK",
        "outputId": "364c1547-b7c2-4937-eda7-04344ee55007"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zJmNXCJEYrvt"
      },
      "outputs": [],
      "source": [
        "drive_image_dir =\"/content/drive/MyDrive/imgs_test_set\" #input Images\n",
        "output_directory=\"/content/drive/MyDrive/imgs_test_set/Detectron2_result/segmented_humans\" #output Folder\n",
        "#make sure we have output dir\n",
        "if not os.path.exists(output_directory):\n",
        "    os.makedirs(output_directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multiply the mask with the original image to extract the segmented person**"
      ],
      "metadata": {
        "id": "N2aFkfZMrunE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List all image files in the directory in Google Drive\n",
        "image_files = [os.path.join(drive_image_dir, filename) for filename in os.listdir(drive_image_dir) if filename.endswith(\".jpeg\")]\n",
        "\n",
        "for image_path in image_files:\n",
        "    # Load an image from Google Drive\n",
        "    im = cv2.imread(image_path)\n",
        "\n",
        "    # Perform inference on the loaded image\n",
        "    outputs = predictor(im)\n",
        "\n",
        "    # Initialize the number of humans detected in the current image\n",
        "    n_human = 0\n",
        "\n",
        "    # Create a copy of the original image\n",
        "    image_with_results = im.copy()\n",
        "\n",
        "    # Filter predictions to only include \"person\" class\n",
        "    filtered_instances = outputs[\"instances\"][outputs[\"instances\"].pred_classes == MetadataCatalog.get(cfg.DATASETS.TRAIN[0]).thing_classes.index(\"person\")]\n",
        "\n",
        "    # Update the number of humans detected\n",
        "    n_human = len(filtered_instances)\n",
        "\n",
        "    # Save segmentation masks of each detected person\n",
        "    for i, mask in enumerate(filtered_instances.pred_masks):\n",
        "        # Convert the PyTorch tensor to a NumPy array\n",
        "        mask_np = mask.cpu().numpy().astype(np.uint8)\n",
        "\n",
        "        # Multiply the mask with the original image to extract the segmented person\n",
        "        segmented_person = cv2.bitwise_and(im, im, mask=mask_np)\n",
        "\n",
        "        # Get the original image name without the extension\n",
        "        image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
        "\n",
        "        # Save the segmented person\n",
        "        save_path = os.path.join(output_directory, f\"{image_name}_person_{i}_segmentation.jpg\")\n",
        "        cv2.imwrite(save_path, segmented_person)\n",
        "\n",
        "    # Print the number of humans detected in the current image\n",
        "    print(f\"Number of humans in {image_path}: {n_human}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46DBi8RLqtv_",
        "outputId": "5b643afb-7fa5-43ef-8e26-91bb83d597af"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of humans in /content/drive/MyDrive/imgs_test_set/1.jpeg: 11\n",
            "Number of humans in /content/drive/MyDrive/imgs_test_set/2.jpeg: 5\n",
            "Number of humans in /content/drive/MyDrive/imgs_test_set/3.jpeg: 8\n",
            "Number of humans in /content/drive/MyDrive/imgs_test_set/4.jpeg: 2\n",
            "Number of humans in /content/drive/MyDrive/imgs_test_set/5.jpeg: 13\n",
            "Number of humans in /content/drive/MyDrive/imgs_test_set/boy-1822565_1280.jpeg: 1\n",
            "Number of humans in /content/drive/MyDrive/imgs_test_set/cmxseT20wDlQ_s600x600.jpeg: 6\n",
            "Number of humans in /content/drive/MyDrive/imgs_test_set/coachplayertf.jpeg: 2\n",
            "Number of humans in /content/drive/MyDrive/imgs_test_set/fef23683-0b70-49d7-8b32-d11ae842f633.jpeg: 3\n",
            "Number of humans in /content/drive/MyDrive/imgs_test_set/images (1).jpeg: 9\n",
            "Number of humans in /content/drive/MyDrive/imgs_test_set/input - Copie.jpeg: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BLACK AND WHITE ?**"
      ],
      "metadata": {
        "id": "s2sF1Oi-rjHr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEe4OBzuZ0ji",
        "outputId": "4e860a8f-6e90-4ad5-ca5c-0cde793b55a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of humans in /content/drive/MyDrive/imgs_test_set/1.jpeg: 11\n",
            "Number of humans in /content/drive/MyDrive/imgs_test_set/2.jpeg: 5\n",
            "Number of humans in /content/drive/MyDrive/imgs_test_set/3.jpeg: 8\n",
            "Number of humans in /content/drive/MyDrive/imgs_test_set/4.jpeg: 2\n",
            "Number of humans in /content/drive/MyDrive/imgs_test_set/5.jpeg: 13\n",
            "Number of humans in /content/drive/MyDrive/imgs_test_set/boy-1822565_1280.jpeg: 1\n",
            "Number of humans in /content/drive/MyDrive/imgs_test_set/cmxseT20wDlQ_s600x600.jpeg: 6\n",
            "Number of humans in /content/drive/MyDrive/imgs_test_set/coachplayertf.jpeg: 2\n",
            "Number of humans in /content/drive/MyDrive/imgs_test_set/fef23683-0b70-49d7-8b32-d11ae842f633.jpeg: 3\n",
            "Number of humans in /content/drive/MyDrive/imgs_test_set/images (1).jpeg: 9\n",
            "Number of humans in /content/drive/MyDrive/imgs_test_set/input - Copie.jpeg: 5\n"
          ]
        }
      ],
      "source": [
        "# List all image files in the directory in Google Drive\n",
        "image_files = [os.path.join(drive_image_dir, filename) for filename in os.listdir(drive_image_dir) if filename.endswith(\".jpeg\")]\n",
        "\n",
        "for image_path in image_files:\n",
        "    # Load an image from Google Drive\n",
        "    im = cv2.imread(image_path)\n",
        "\n",
        "    # Perform inference on the loaded image\n",
        "    outputs = predictor(im)\n",
        "\n",
        "    # Initialize the number of humans detected in the current image\n",
        "    n_human = 0\n",
        "\n",
        "    # Create a copy of the original image\n",
        "    image_with_results = im.copy()\n",
        "\n",
        "    # Filter predictions to only include \"person\" class\n",
        "    filtered_instances = outputs[\"instances\"][outputs[\"instances\"].pred_classes == MetadataCatalog.get(cfg.DATASETS.TRAIN[0]).thing_classes.index(\"person\")]\n",
        "\n",
        "    # Update the number of humans detected\n",
        "    n_human = len(filtered_instances)\n",
        "\n",
        "    # Save segmentation masks of each detected person\n",
        "    for i, mask in enumerate(filtered_instances.pred_masks):\n",
        "        # Convert the PyTorch tensor to a NumPy array and then to a 3-channel mask\n",
        "        mask = np.repeat(mask.cpu().numpy()[:, :, np.newaxis], 3, axis=2) * 255\n",
        "\n",
        "        # Get the original image name without the extension\n",
        "        image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
        "\n",
        "        # Save the segmentation mask in your Google Drive directory with the original image name and person index\n",
        "        save_path = os.path.join(output_directory, f\"{image_name}_person_{i}_mask.jpg\")\n",
        "        cv2.imwrite(save_path, mask.astype(np.uint8))\n",
        "\n",
        "    # Print the number of humans detected in the current image\n",
        "    print(f\"Number of humans in {image_path}: {n_human}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}